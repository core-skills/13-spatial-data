{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geospatial data processing\n",
    "\n",
    "Today we're going to look at pulling climate statistics out for suburbs from a shapefile. First let's look at the libraries we're going to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if using jupyterhub\n",
    "# %pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas\n",
    "import shapely\n",
    "import pandas\n",
    "import rasterio\n",
    "import affine\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're using `geopandas` to manage the vector data, and `rasterio` to manage the raster data. You can find the documentation for these libraries here:\n",
    "\n",
    "- [`geopandas` documentation](http://geopandas.org) - uses `shapely` and `pandas` under the hood to manage geometries and tabular attributes respectively.\n",
    "- [`rasterio` documentation](https://rasterio.readthedocs.io/en/latest/) - uses `numpy` and `affine` under the hood to manage arrays and transformations respectively.\n",
    "\n",
    "Feel free to have a browse around and see what else these libraries can do for you. There's also a specialized StackExchange (like a subreddit for StackOverflow) on geospatial stuff here: https://gis.stackexchange.com which typically has a higher signal-to-noise ratio if you get stuck."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading and parsing BoM climate data\n",
    "\n",
    "I've downloaded the BoM data for Australia from here: http://www.bom.gov.au/jsp/ncc/climate_averages/temperature/index.jsp?maptype=3&period=aut#maps\n",
    "\n",
    "BoM, in it's own wisdom, uses a Grid text file which has no useful geospatial aspects so we need a seperate function to put it into a useful format. Feel free to dumpster dive if you want to see how to generate your own geotiffs from numpy arrays otherwise just ignore this function and treat it as a black-box conversion service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_to_geotiff(filename, return_data=False):\n",
    "    \"\"\" Load data from a Bureau of Meterology 'grid' file and dump out to geotiff\n",
    "        Output is written to geotiff\n",
    "        Parameters:\n",
    "            filename - the file name of the BoM grid file to convert\n",
    "            return_data - if true, then a Numpy array with the imported\n",
    "                data is returned when conversion is successful.\n",
    "    \"\"\"\n",
    "    # First six lines are metadata\n",
    "    # Note: gonna assume the origin is WGS84\n",
    "    with open(filename) as fhandle:\n",
    "        meta = {}\n",
    "        for line in fhandle:\n",
    "            key, value = line.split()\n",
    "            key = key.lower()\n",
    "            meta[key] = value\n",
    "            if len(meta) == 6:\n",
    "                break\n",
    "\n",
    "    # Handle sloppy labelling from BoM\n",
    "    for idx in ('x', 'y'):\n",
    "        if meta.get(idx + 'llcorner') is not None:\n",
    "            meta[idx + 'llcenter'] = meta[idx + 'llcorner']\n",
    "\n",
    "    # Convert metadata to right format\n",
    "    type_mapping = {'ncols': int, 'nrows': int,\n",
    "                    'xllcenter': float, 'yllcenter': float,\n",
    "                    'cellsize': float, 'nodata_value': float}\n",
    "    for key, typef in type_mapping.items():\n",
    "        meta[key] = typef(meta[key])\n",
    "\n",
    "    # Next lines are info - swap out nodata with nans\n",
    "    # Last lines are also metadata 'header' but we don't care about that\n",
    "    data = np.genfromtxt(filename, dtype=np.float64,\n",
    "                            skip_header=6, skip_footer=18)\n",
    "\n",
    "    # Check whether we have masked values to deal with\n",
    "    has_mask = (meta.get('nodata_value') is not None)\n",
    "    if has_mask:\n",
    "        has_mask = True\n",
    "        nodata_mask = (data - meta['nodata_value']) ** 2 < 1e-6\n",
    "\n",
    "    ## MAKE GEOTIFF\n",
    "    # Generate the transform for the grid\n",
    "    aff = affine.Affine.translation(\n",
    "        meta['xllcenter'] - meta['cellsize'] * 0.5,\n",
    "        meta['yllcenter'] + (meta['nrows'] - 0.5) * meta['cellsize']\n",
    "    ) * affine.Affine.scale(meta['cellsize'], -meta['cellsize'])\n",
    "\n",
    "    # Make metadata for geotiff\n",
    "    geotiff_meta = {\n",
    "        'transform': aff,\n",
    "        'width': meta['ncols'],\n",
    "        'height': meta['nrows'],\n",
    "        'nodata': meta['nodata_value'],\n",
    "        'tiled': 'no',\n",
    "        'crs': {'init': 'epsg:4326'},  # assuming WGS84\n",
    "        'driver': 'GTiff',\n",
    "        'dtype': 'float64',\n",
    "        'blockxsize': 128,\n",
    "        'blockysize': 128,\n",
    "        'count': 1\n",
    "    }\n",
    "\n",
    "    # Write out to file\n",
    "    with rasterio.open(filename + '.geotiff', 'w', **geotiff_meta) as sink:\n",
    "        sink.write_band(1, data)\n",
    "        if has_mask:\n",
    "            sink.write_mask(nodata_mask.astype(bool))\n",
    "\n",
    "    # If we're returning the data, convert data mask to np.nan\n",
    "    if return_data:\n",
    "        if has_mask:\n",
    "            data[nodata_mask] = np.nan\n",
    "        return data\n",
    "    else:\n",
    "        return filename + '.geotiff'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets use this importer to read the grid file and convert it to a georeferenced GeoTIFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'spring': grid_to_geotiff('../data/minspr.txt', return_data=True),\n",
    "    'summer': grid_to_geotiff('../data/minsum.txt', return_data=True),\n",
    "    'autumn': grid_to_geotiff('../data/minaut.txt', return_data=True),\n",
    "    'winter': grid_to_geotiff('../data/minwin.txt', return_data=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can show a quick-and-dirty plot of Australia's minimum temperatures for each season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the min and maximum so everything uses the same scale\n",
    "min_temp = -1\n",
    "max_temp = 20\n",
    "\n",
    "# Generate the plots for each season\n",
    "fig, axes = plt.subplots(1, 4)\n",
    "for (title, temps), ax in zip(data.items(), axes):\n",
    "    ax.imshow(temps, vmin=min_temp, vmax=max_temp)\n",
    "    ax.set_title(title)\n",
    "    ax.set_axis_off()\n",
    "fig.set_size_inches(12, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting a suburbs shapefile for Perth\n",
    "\n",
    "We're going to use the suburbs shapefile to extract portions of these temperature maps for Perth. You can see the info page on `data.gov.au` here: https://data.gov.au/dataset/wa-suburb-locality-boundaries-psma-administrative-boundaries\n",
    "\n",
    "First, download and extract the shapefile, then you can use `geopandas` to read it just like you'd use `pandas` to read a normal CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "# Download the file in a temporary folder\n",
    "url = 'https://data.gov.au/data/dataset/6a0ec945-c880-4882-8a81-4dbcb85e74e5/resource/141fc7bd-c75f-49b5-a116-35250eea68cd/download/wa_locality_polygon_shp.zip'\n",
    "filepath, _ = urllib.request.urlretrieve(url)\n",
    "# Unzip it in the data folder\n",
    "with zipfile.ZipFile(filepath, 'r') as file:\n",
    "    file.extractall(path='../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suburbs = geopandas.read_file('../data/wa_localities.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at what we've got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suburbs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we can see is that there is a bunch of rows, each with potentially useful information. The key difference is the `geometry` column - this is a set of shapes which contains a 'geometry' for the suburb - in this case a polygon representing the suburb outline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick and dirty map of our suburbs\n",
    "suburbs.plot(figsize=(12, 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at an individual suburb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suburb = suburbs[suburbs.LOC_PID == 'locc358bce007c6'].iloc[0]  # let's play with Perth's CBD\n",
    "suburb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suburb.geometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This geometry is a regular shapely shape and we can access a whole bunch of analytics from here. For example we can get the boundary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suburb.geometry.boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could buffer on this boundary to find locations within a certain distance of the suburb edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "near_boundary = suburb.geometry.boundary.buffer(0.001)\n",
    "near_boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we only care about properties inside the suburb we can generate the intersection of the buffer with the suburb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suburb.geometry.intersection(near_boundary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get the suburb centroid etc etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suburb.geometry.centroid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically anything you could think of doing in ArcGIS you can do in Python, with the added advantage of all the machine learning/statistical/data science libraries that you can leverage to do really complex stuff. \n",
    "\n",
    "Have a play with the attributes here and also take a look at the [`shapely` documentation for more spatial analysis methods](https://shapely.readthedocs.io/en/stable/manual.html#spatial-analysis-methods)\n",
    "\n",
    "### Getting temperature data for the suburb\n",
    "\n",
    "Next we're going to look at using Rasterio to pull out the temperature pixels for each suburb. \n",
    "\n",
    "Before we generate the masks we need to make sure that the polygons and the rasters have the same projection. Fortunately `geopandas` makes this easy for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the initial suburb coordinate reference system\n",
    "suburbs.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to EPSG 4326 (Web Mercator, aka EPSG:900913)\n",
    "suburbs.to_crs(epsg=4326, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull out our suburb again\n",
    "suburb = suburbs[suburbs.LOC_PID == 'locc358bce007c6'].iloc[0]\n",
    "suburb.geometry  # this will look the same but the numbers are diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key piece of functionality we want is in `rasterio.rasterize` (funnily enough my search for copy-paste code [led me to a GitHub issue I contributed to in 2014](https://github.com/mapbox/rasterio/issues/154) - it's nice when past you makes your job easier). Basically we create a mask for the image by burning the polygons into the raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterio.features import rasterize\n",
    "\n",
    "# Generate mask using first image for metadata\n",
    "mask_value = 1\n",
    "fill_value = 0\n",
    "with rasterio.open('../data/minaut.txt.geotiff') as src:\n",
    "    mask = rasterize([(suburb.geometry.__geo_interface__, mask_value)], \n",
    "                     out_shape=src.shape, \n",
    "                     transform=src.transform, \n",
    "                     all_touched=True, \n",
    "                     fill=fill_value).astype(bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there might not be many pixels touched by the polygon at this scale, but they're the right ones that we want!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(mask) # see how many pixels we've picked up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the mask to select the relevant pixels out of the geotiff to get temperature data for the suburb for each season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    ('autumn', '../data/minaut.txt.geotiff'),\n",
    "    ('spring', '../data/minspr.txt.geotiff'),\n",
    "    ('summer', '../data/minsum.txt.geotiff'),\n",
    "    ('winter', '../data/minwin.txt.geotiff')\n",
    "]\n",
    "\n",
    "results = {}\n",
    "for key, filename in datasets:\n",
    "    with rasterio.open(filename) as src:\n",
    "        results[key] = src.read(1)[mask]\n",
    "    \n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Write a function to do this data extraction for all the suburbs in the shapefile with feeding it to a machine learning pipeline in mind. The function should return a pandas dataframe with the LOC_PID of the suburbs, the coordinates of their centroids, and the mean temperatures for each season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
